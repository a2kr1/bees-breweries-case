
<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8">
  <title>DocumentaÃ§Ã£o TÃ©cnica â€“ Projeto BEES</title>
  <style>
    body {
      background-color: #FFF8F0;
      color: #333;
      font-family: 'Segoe UI', sans-serif;
      padding: 2rem;
    }
    h1, h2, h3 {
      color: #7C0A02;
    }
    pre {
      background: #f4f4f4;
      padding: 1rem;
      border-left: 4px solid #D6A900;
      overflow-x: auto;
    }
    code {
      background: #eee;
      padding: 2px 4px;
      border-radius: 3px;
    }
    a {
      color: #593C1F;
    }
    hr {
      margin: 2rem 0;
    }
  </style>
</head>
<body>
<main>
<br>
# ğŸ“˜ DocumentaÃ§Ã£o TÃ©cnica â€“ Projeto BEES Breweries Case<br>
<br>
Este documento apresenta as principais decisÃµes tÃ©cnicas, arquitetura e estratÃ©gias utilizadas no desenvolvimento do case tÃ©cnico de Engenharia de Dados para a BEES.<br>
<br>
---<br>
<br>
## ğŸ”§ Escolhas TÃ©cnicas<br>
<br>
### 1. PySpark + Delta Lake como Plataforma Principal<br>
- UtilizaÃ§Ã£o do PySpark como motor de processamento distribuÃ­do.<br>
- Armazenamento com Delta Lake em disco local, permitindo versionamento, transaÃ§Ãµes ACID e escrita particionada.<br>
- Ideal para simular um ambiente de produÃ§Ã£o mesmo sem Databricks.<br>
<br>
### 2. Armazenamento Local com Delta Lake<br>
- Os dados foram salvos em disco no formato Delta, organizados por camadas e particionados por `processing_date` e `state`.<br>
- BenefÃ­cios:<br>
  - Desempenho otimizado para leitura e escrita.<br>
  - Facilidade para simular ambiente Data Lake em arquitetura Medallion.<br>
  - Permite auditoria e rollback com controle de versÃ£o de dados.<br>
<br>
### 3. OrquestraÃ§Ã£o com Apache Airflow<br>
- UtilizaÃ§Ã£o do Airflow com DAG Ãºnica (`brewery_dag.py`) para orquestrar todo o pipeline.<br>
- ExecuÃ§Ã£o sequencial: Bronze â†’ Silver â†’ Gold â†’ VerificaÃ§Ãµes<br>
- Flexibilidade para execuÃ§Ã£o agendada ou manual.<br>
<br>
### 4. ContainerizaÃ§Ã£o com Docker<br>
- Todo o projeto pode ser executado via `docker-compose`.<br>
- CriaÃ§Ã£o de ambiente isolado, com dependÃªncias resolvidas.<br>
- Inclui serviÃ§os de Spark, Airflow, e dashboard EDA.<br>
<br>
---<br>
<br>
## ğŸ—ï¸ Arquitetura em Camadas (Medallion)<br>
<br>
### ğŸŸ« Bronze<br>
- IngestÃ£o direta da API Open Brewery DB (paginada).<br>
- Armazenamento de arquivos JSON brutos com controle por data.<br>
<br>
### ğŸŸª Silver<br>
- Leitura resiliente dos arquivos da Bronze.<br>
- NormalizaÃ§Ã£o dos dados e escrita em formato Delta particionado por `processing_date` e `state`.<br>
- AplicaÃ§Ã£o de regras de schema e eliminaÃ§Ã£o de duplicatas.<br>
<br>
### ğŸŸ¨ Gold<br>
- AgregaÃ§Ãµes analÃ­ticas por `state` e `brewery_type`.<br>
- Escrita em Delta particionado por `processing_date`.<br>
<br>
---<br>
<br>
## ğŸ“‘ Metadados e Versionamento<br>
<br>
### Armazenamento Delta<br>
- Cada tabela Delta permite versionamento e histÃ³rico de alteraÃ§Ãµes (Time Travel).<br>
- Acesso a snapshots com controle de schema evolution.<br>
<br>
### Metadados<br>
- Estrutura padrÃ£o adotada para as colunas (ex: nomes consistentes entre camadas).<br>
- UtilizaÃ§Ã£o de comentÃ¡rios nas colunas no modo `full` para documentaÃ§Ã£o via `ALTER COLUMN`.<br>
<br>
---<br>
<br>
## ğŸ§ª VerificaÃ§Ãµes de Qualidade<br>
<br>
- Scripts automatizados de validaÃ§Ã£o com `pytest` e `verify_all.py`.<br>
- VerificaÃ§Ãµes implementadas:<br>
  - ExistÃªncia de dados<br>
  - PresenÃ§a de valores nulos<br>
  - Checagem de duplicatas<br>
  - ValidaÃ§Ã£o de schema<br>
<br>
---<br>
<br>
## ğŸ“Š Dashboard EDA<br>
<br>
- VisualizaÃ§Ã£o simples via HTML, acessÃ­vel em: `http://localhost:8080/eda`<br>
- PÃ¡gina estÃ¡tica configurada via `webserver_config.py` no Airflow.<br>
- PossÃ­vel integraÃ§Ã£o com dados da Silver em tempo real.<br>
<br>
---<br>
<br>
## âš™ï¸ ExecuÃ§Ã£o<br>
<br>
### Via Docker<br>
```bash<br>
docker compose build<br>
docker compose up -d<br>
```<br>
<br>
### ExecuÃ§Ã£o manual por container<br>
```bash<br>
docker exec -e PROCESSING_DATE=2025-07-30 -it spark-container python3 /home/project/scripts/run_bronze.py<br>
docker exec -e PROCESSING_DATE=2025-07-30 -e CARGA=delta -it spark-container python3 /home/project/scripts/run_silver.py<br>
docker exec -e PROCESSING_DATE=2025-07-30 -e CARGA=delta -it spark-container python3 /home/project/scripts/run_gold.py<br>
docker exec -e PROCESSING_DATE=2025-07-30 -it spark-container python3 /home/project/tests/verify_all.py<br>
```<br>
<br>
---<br>
<br>
## ğŸ“ Estrutura dos DiretÃ³rios<br>
<br>
```<br>
bees-breweries-case/<br>
â”œâ”€â”€ airflow/<br>
â”‚   â”œâ”€â”€ dags/<br>
â”‚   â”œâ”€â”€ static/<br>
â”‚   â””â”€â”€ config/webserver_config.py<br>
â”œâ”€â”€ data/<br>
â”‚   â”œâ”€â”€ bronze/<br>
â”‚   â”œâ”€â”€ silver/<br>
â”‚   â””â”€â”€ gold/<br>
â”œâ”€â”€ scripts/<br>
â”œâ”€â”€ src/<br>
â”œâ”€â”€ tests/<br>
â”œâ”€â”€ Dockerfile<br>
â”œâ”€â”€ docker-compose.yml<br>
â””â”€â”€ Makefile<br>
```<br>
<br>
---<br>
<br>
## ğŸ‘¨â€ğŸ’» Autor<br>
<br>
**AndrÃ© Santos**  <br>
Engenheiro de Dados | [github.com/a2kr1](https://github.com/a2kr1)<br>

</main>
</body>
</html>
